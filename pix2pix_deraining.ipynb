{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNVaa3D3Xe5m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "2a1120a6-e8f1-42bc-d124-e84d0f810fd3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKd_aRUHPFAP"
      },
      "source": [
        "#ls gdrive/'My Drive'/raindrop_data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOuHBtH0XoMj"
      },
      "source": [
        "from shutil import copyfile\n",
        "#copyfile('gdrive/My Drive/dl_proj_data/RAIN_DATASET_v5.zip', 'RAIN_DATASET_v5.zip')\n",
        "#copyfile('gdrive/My Drive/raindrop_data/test_a.zip', 'test_a.zip')\n",
        "#copyfile('gdrive/My Drive/raindrop_data/test_b.zip', 'test_b.zip')\n",
        "#copyfile('gdrive/My Drive/raindrop_data/train.zip', 'train.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc1MpRy2Y-1v"
      },
      "source": [
        "#!unzip RAIN_DATASET_v5.zip\n",
        "#!unzip train.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEPkNsvHQa5K"
      },
      "source": [
        "#ls train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUGwHAo_aH3U"
      },
      "source": [
        "#ls RAIN_DATASET/ALIGNED_PAIRS/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nbLeDbAyFSO"
      },
      "source": [
        "#mkdir data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IR3WNAQw7Jo-"
      },
      "source": [
        "#ls data/CLEAN/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTso7mr9yAAf"
      },
      "source": [
        "#cp -R RAIN_DATASET/ALIGNED_PAIRS/CLEAN data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1ywkYNq8Jtm"
      },
      "source": [
        "#cp -R RAIN_DATASET/ALIGNED_PAIRS/CG_DROPLETS data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-zkXlbKgWV7"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "from torchvision import datasets,models,transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import random\n",
        "from skimage.measure import compare_psnr, compare_ssim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lW6pLCPliDpW"
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "\n",
        "class Reshape(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(-1,1,input_shape[0],input_shape[1])\n",
        "      \n",
        "def conv_block(in_channels, out_channels,kernel=3,stride=2,padding=1):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels,kernel ,stride,padding=padding),\n",
        "        nn.InstanceNorm2d(out_channels),\n",
        "        nn.LeakyReLU(0.2,True)\n",
        "    )\n",
        "def conv_block_noNorm(in_channels, out_channels,kernel=3,stride=2,padding=1):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels,kernel ,stride,padding=padding),\n",
        "        nn.LeakyReLU(0.2,True)\n",
        "    )\n",
        "def conv_block_noAct(in_channels, out_channels,kernel=3,stride=2,padding=1):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels,kernel ,stride,padding=padding),\n",
        "        nn.InstanceNorm2d(out_channels),\n",
        "    )\n",
        "def conv_block2(in_channels, out_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels,3,padding=1),\n",
        "        nn.InstanceNorm2d(out_channels),\n",
        "        nn.LeakyReLU(0.2,True)\n",
        "    ) \n",
        "  \n",
        "\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "      \n",
        "class resnet_block(nn.Module):\n",
        "    def __init__(self,in_ch,out_ch):\n",
        "        super(resnet_block, self).__init__()\n",
        "        self.pad=nn.ReflectionPad2d(1)\n",
        "        self.econv1=conv_block(in_ch,out_ch,stride=1,padding=0)\n",
        "        self.econv2=conv_block_noAct(out_ch, out_ch,stride=1,padding=0)\n",
        "    \n",
        "    def forward(self, input):\n",
        "      conv=self.pad(input)\n",
        "      conv = self.econv1(conv)\n",
        "      conv=self.pad(conv)\n",
        "      conv=self.econv2(conv)\n",
        "      return conv+input\n",
        "\n",
        "\n",
        "      return input\n",
        "'''\n",
        "def custom_conv2d_padded(in_channels, out_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 1, 1),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "'''\n",
        "def custom_conv2dTranspose(in_channels, out_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_channels, out_channels, 3,2,padding=1,output_padding=1),\n",
        "        nn.InstanceNorm2d(out_channels),\n",
        "        nn.LeakyReLU(0.2,True)\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbrpByp8htPV"
      },
      "source": [
        "class pix2pix(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(pix2pix, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.reflectpad3=nn.ReflectionPad2d(3)\n",
        "        self.econv1=conv_block(3,32,kernel=7,stride=1,padding=0)\n",
        "        self.econv2=conv_block(32,64)\n",
        "        self.econv3=conv_block(64,128)\n",
        "        self.econv4=conv_block(128,256)\n",
        "        self.resnet1=resnet_block(256,256)\n",
        "        self.resnet2=resnet_block(256,256)\n",
        "        self.resnet3=resnet_block(256,256)\n",
        "        self.resnet4=resnet_block(256,256)\n",
        "        self.resnet5=resnet_block(256,256)\n",
        "        self.resnet6=resnet_block(256,256)\n",
        "        self.resnet7=resnet_block(256,256)\n",
        "        self.resnet8=resnet_block(256,256)\n",
        "        self.resnet9=resnet_block(256,256)\n",
        "        #self.dconv1=conv_block2(32,3)\n",
        "        #self.dconv2=conv_block2(64,32)\n",
        "        #self.dconv3=conv_block2(128,64)\n",
        "        #self.dconv4=conv_block2(256,128)\n",
        "        self.upsample4=custom_conv2dTranspose(256,128)\n",
        "        self.upsample3=custom_conv2dTranspose(256,64)\n",
        "        self.upsample2=custom_conv2dTranspose(128,32)\n",
        "        self.econv5=conv_block(64,3,kernel=7,stride=1,padding=0)\n",
        "        #self.upsample1=custom_conv2dTranspose(64,3)\n",
        "        #self.crop   = torch.nn.ReflectionPad2d((0,-15,0,-15))\n",
        "        #self.output_layer1=custom_conv2d_padded(16*2**(0), 1)\n",
        "        #self.output_layer2=custom_conv2d_padded(16*2**(0), 1)\n",
        "    \n",
        "    def forward(self, input):\n",
        "      input=self.reflectpad3(input)\n",
        "      #print('input ',input.size())\n",
        "      conv1 = self.econv1(input)\n",
        "      #print('econv1',conv1.size())\n",
        "\n",
        "      conv2 = self.econv2(conv1)\n",
        "      #print('econv2',conv2.size())\n",
        "\n",
        "      conv3 = self.econv3(conv2)\n",
        "      #print('econv3',conv3.size())\n",
        "\n",
        "      conv4 = self.econv4(conv3)\n",
        "      #print('econv4',conv4.size())\n",
        "      resnet1=self.resnet1(conv4)\n",
        "      resnet2=self.resnet2(resnet1)\n",
        "      resnet3=self.resnet3(resnet2)\n",
        "      resnet4=self.resnet4(resnet3)\n",
        "      resnet5=self.resnet5(resnet4)\n",
        "      resnet6=self.resnet6(resnet5)\n",
        "      resnet7=self.resnet7(resnet6)\n",
        "      resnet8=self.resnet8(resnet7)\n",
        "      resnet9=self.resnet9(resnet8) \n",
        "      #print('resnet',resnet1.size())\n",
        "      input = self.upsample4(resnet9)\n",
        "      #print('upsample4',input.size())\n",
        "      input= torch.cat([input, conv3], dim=1)\n",
        "      #print('cat',input.size())\n",
        "      #input=self.dconv4(input)\n",
        "      #print('dconv4',input.size())\n",
        "      input= self.upsample3(input)   \n",
        "      #print('upsample3',input.size())\n",
        "      input = torch.cat([input, conv2], dim=1) \n",
        "      #print('cat',input.size())\n",
        "      #input=self.dconv3(input)\n",
        "      #print('dconv3',input.size())\n",
        "\n",
        "      input = self.upsample2(input)  \n",
        "      #print('upsample2',input.size())\n",
        "\n",
        "      input = torch.cat([input, conv1], dim=1)\n",
        "      #print(input.size())\n",
        "      #input=self.dconv2(input)\n",
        "      #print('dconv2',input.size())\n",
        "      input=self.reflectpad3(input)\n",
        "      input = self.econv5(input)  \n",
        "      #print('econv5',input.size())\n",
        "      #input = torch.cat([input, conv1], dim=1)\n",
        "      #print(input.size())\n",
        "      #print('output size',input.size())\n",
        "      #print('output size',input.size())\n",
        "      return input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ru4LGX45luWy"
      },
      "source": [
        "ngpu=1\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
        "netG = pix2pix(ngpu).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4FZVo5yl09C"
      },
      "source": [
        "#temp=torch.randn(4,3,320,320 ,device=device)\n",
        "#a=netG(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhwICf93O-uj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "outputId": "add1dccb-c566-43b9-8f2a-d5c3ee4f561c"
      },
      "source": [
        "\n",
        "class patchgan_disc(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "      super(patchgan_disc, self).__init__()\n",
        "      self.ngpu = ngpu\n",
        "      self.conv1=conv_block_noNorm(3,64,kernel=3,stride=2,padding=0)\n",
        "      self.conv2=conv_block(64,128,kernel=3,stride=2,padding=0)\n",
        "      self.conv3=conv_block(128,256,kernel=3,stride=2,padding=0)\n",
        "      self.conv4=conv_block(256,512,kernel=3,stride=2,padding=0)\n",
        "      self.conv5=nn.Conv2d(512, 1,3,stride=2,padding=0)\n",
        "    \n",
        "    def forward(self, input):\n",
        "      input=self.conv1(input)\n",
        "      input=self.conv2(input)\n",
        "      input=self.conv3(input)\n",
        "      input=self.conv4(input)\n",
        "      input=self.conv5(input)\n",
        "\n",
        "      return input\n",
        "'''\n",
        "class patchgan_disc(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "      super(patchgan_disc, self).__init__()\n",
        "      self.ngpu = ngpu\n",
        "      self.conv1=conv_block_noNorm(3,64,kernel=4,stride=2,padding=0)\n",
        "      self.conv2=conv_block(64,128,kernel=4,stride=2,padding=0)\n",
        "      self.conv3=conv_block(128,256,kernel=4,stride=2,padding=0)\n",
        "      self.conv4=conv_block(256,512,kernel=4,stride=1,padding=0)\n",
        "      self.conv5=conv_block(512,1,kernel=4,stride=1,padding=0)\n",
        "      self.flatten=Flatten()\n",
        "      self.linear1=nn.Linear(2704,1024)\n",
        "      self.act1=nn.LeakyReLU(0.2,True)\n",
        "      self.linear2=nn.Linear(1024, 1)\n",
        "      self.act2=nn.Sigmoid()\n",
        "    def forward(self, input):\n",
        "      input=self.conv1(input)\n",
        "      input=self.conv2(input)\n",
        "      input=self.conv3(input)\n",
        "      input=self.conv4(input)\n",
        "      input=self.conv5(input)\n",
        "      input=self.flatten(input)\n",
        "      input=self.linear1(input)\n",
        "      input=self.act1(input)\n",
        "      input=self.linear2(input)\n",
        "      input=self.act2(input)\n",
        "      return input\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nclass patchgan_disc(nn.Module):\\n    def __init__(self, ngpu):\\n      super(patchgan_disc, self).__init__()\\n      self.ngpu = ngpu\\n      self.conv1=conv_block_noNorm(3,64,kernel=4,stride=2,padding=0)\\n      self.conv2=conv_block(64,128,kernel=4,stride=2,padding=0)\\n      self.conv3=conv_block(128,256,kernel=4,stride=2,padding=0)\\n      self.conv4=conv_block(256,512,kernel=4,stride=1,padding=0)\\n      self.conv5=conv_block(512,1,kernel=4,stride=1,padding=0)\\n      self.flatten=Flatten()\\n      self.linear1=nn.Linear(2704,1024)\\n      self.act1=nn.LeakyReLU(0.2,True)\\n      self.linear2=nn.Linear(1024, 1)\\n      self.act2=nn.Sigmoid()\\n    def forward(self, input):\\n      input=self.conv1(input)\\n      input=self.conv2(input)\\n      input=self.conv3(input)\\n      input=self.conv4(input)\\n      input=self.conv5(input)\\n      input=self.flatten(input)\\n      input=self.linear1(input)\\n      input=self.act1(input)\\n      input=self.linear2(input)\\n      input=self.act2(input)\\n      return input\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcCtpC0gOLWh"
      },
      "source": [
        "netD=patchgan_disc(ngpu).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59U-ACoiOKIr"
      },
      "source": [
        "#temp=torch.randn(4,3,320,320 ,device=device)\n",
        "#a=netD(temp)\n",
        "#b=a.view(-1).size()\n",
        "#print(list(b)[0])\n",
        "#asd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpCLvp5hOlEC"
      },
      "source": [
        "class disc_loss_func(nn.Module):\n",
        "    def __init__(self,ngpu):\n",
        "        super(disc_loss_func, self).__init__()\n",
        "    \n",
        "    def forward(self,rainy,clean,netD):\n",
        "      clean=netD(clean)\n",
        "      #gen_label=torch.tensor(0.0).expand_as(rainy).to(device)\n",
        "      clean_label=torch.tensor(1.0).expand_as(clean).to(device)\n",
        "      loss=(( rainy**2) + ((clean-clean_label)**2)).mean()\n",
        "      return loss\n",
        "  \n",
        "class gen_loss_func(nn.Module):\n",
        "    def __init__(self,ngpu,vgg_model):\n",
        "        super(gen_loss_func, self).__init__()\n",
        "        #self.vgg_layers = vgg_model.features\n",
        "        self.vgg_model=vgg_model\n",
        "        #self.netD=netD.features\n",
        "    \n",
        "    def forward(self,rainy,clean,netG,netD): #rainy is D (G (rainy )) \n",
        "      generated=netG(rainy)\n",
        "      \n",
        "      Le=(generated-clean)**2\n",
        "      div=list(generated.view(-1).size())[0]\n",
        "      Le=Le.sum()/div\n",
        "      #Le=Le.mean()\n",
        "      \n",
        "      rainy=netD(generated)\n",
        "      real_label=torch.tensor(1.0).expand_as(rainy).to(device)\n",
        "      adv_loss= ((rainy-real_label)**2).mean()\n",
        "      nvgg=31#50#31\n",
        "      i=0\n",
        "      Lperc=0\n",
        "      scale=1e6\n",
        "      temp_generated=generated\n",
        "      temp_clean=clean\n",
        "      #temp_generated=temp_generated*255.0\n",
        "      #temp_clean=temp_clean*255.0\n",
        "      '''\n",
        "      for name, module in self.vgg_layers._modules.items():\n",
        "            w=2**(nvgg-i)\n",
        "            i=i+1\n",
        "            temp_generated = module(temp_generated)\n",
        "            div=list(temp_generated.view(-1).size())[0]\n",
        "            temp_clean = module(temp_clean)\n",
        "      '''\n",
        "      temp_generated=self.vgg_model(generated)\n",
        "      temp_clean=self.vgg_model(temp_clean)\n",
        "      temp=((temp_generated-temp_clean)**2).sum()\n",
        "      #print(temp)\n",
        "      #temp=temp/scale\n",
        "      temp=temp/div\n",
        "      Lperc=Lperc+temp\n",
        "      '''     \n",
        "      nlayers=15#28#5\n",
        "      i=0\n",
        "      Lmsadv=0\n",
        "      temp_generated=generated\n",
        "      temp_clean=clean\n",
        "      #temp_generated=temp_generated*255.0\n",
        "      #temp_clean=temp_clean*255.0\n",
        "      for module in netD.children():\n",
        "            w=2**(nlayers-i)\n",
        "            i=i+1\n",
        "            temp_generated = module(temp_generated)\n",
        "            div=list(temp_generated.view(-1).size())[0]\n",
        "            temp_clean = module(temp_clean)\n",
        "            temp=torch.abs(temp_generated-temp_clean).sum()\n",
        "            #temp=temp/scale\n",
        "            temp=temp/(w*div)\n",
        "            Lmsadv=Lmsadv+temp\n",
        "      '''\n",
        "      #print(0.001*adv_loss.item(),Le.item(),Lperc.item())#,Lmsadv.item())\n",
        "      loss=0.01*adv_loss+Lperc+Le#+Lmsadv\n",
        "      return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eh44NEVV9SQS"
      },
      "source": [
        "#f#or module in netD.children():\n",
        "  #print(module)\n",
        "  #asd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DllFNZGbVJVt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "a2618b0b-2b1b-457f-c30c-43d0c93a4453"
      },
      "source": [
        "epochs=100000\n",
        "batch=1\n",
        "lr_gen=0.0001\n",
        "lr_disc=0.0001\n",
        "display=500\n",
        "def trainable(net, trainable):\n",
        "    for para in net.parameters():\n",
        "        para.requires_grad = trainable\n",
        "vgg_model = models.vgg16(pretrained=True)\n",
        "vgg_model = torch.nn.Sequential(*(list(vgg_model.children())[:-2]))\n",
        "trainable(vgg_model, False)\n",
        "disc_loss=disc_loss_func(ngpu).to(device)\n",
        "gen_loss=gen_loss_func(ngpu,vgg_model).to(device)\n",
        "optimizer_G = torch.optim.Adam(netG.parameters(), lr=lr_gen)\n",
        "optimizer_D = torch.optim.Adam(netD.parameters(), lr=lr_disc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 553433881/553433881 [00:04<00:00, 137265522.83it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnhgyHv5egxf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "outputId": "ea6d9683-919c-4e82-b4f7-91e2cc80002a"
      },
      "source": [
        "'''\n",
        "data_transform = transforms.Compose([\n",
        "        transforms.Resize((640,640)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "dataset = datasets.ImageFolder(root='data/',\n",
        "                                           transform=data_transform)\n",
        "dataset_loader = torch.utils.data.DataLoader(dataset,\n",
        "                                             batch_size=batch, shuffle=True,\n",
        "                                             num_workers=0)\n",
        "data_iter=iter(dataset_loader)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndata_transform = transforms.Compose([\\n        transforms.Resize((640,640)),\\n        transforms.ToTensor()\\n    ])\\ndataset = datasets.ImageFolder(root='data/',\\n                                           transform=data_transform)\\ndataset_loader = torch.utils.data.DataLoader(dataset,\\n                                             batch_size=batch, shuffle=True,\\n                                             num_workers=0)\\ndata_iter=iter(dataset_loader)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-39qV3FruYUq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "outputId": "fe66fc96-53ed-4947-e6ef-a4ff4a0797b0"
      },
      "source": [
        "\n",
        "class data_load():\n",
        "    def __init__(self,path_to_clean='data/',batch=5):\n",
        "        super(data_load, self).__init__()\n",
        "        self.clean_files=glob(path_to_clean+'CLEAN/'+'*')\n",
        "        self.path_to_clean=path_to_clean\n",
        "        self.batch=batch\n",
        "        \n",
        "    def next(self):\n",
        "        size=480\n",
        "        clean_imgs=np.zeros((self.batch,3,size,size))\n",
        "        rainy_imgs=np.zeros((self.batch,3,size,size))\n",
        "        for i in range(self.batch):\n",
        "          flip_rand=random.randint(0,2)\n",
        "          index=random.randint(0,len(self.clean_files)-1)\n",
        "          single_clean=self.clean_files[index][15:]\n",
        "          rainy_path=self.path_to_clean+'CG_DROPLETS/left'+single_clean\n",
        "          rainy_img=cv2.imread(rainy_path)\n",
        "          x_rand=random.randint(0,rainy_img.shape[0]-size)\n",
        "          y_rand=random.randint(0,rainy_img.shape[1]-size)\n",
        "          rainy_img=rainy_img[x_rand:x_rand+size,y_rand:y_rand+size,:]\n",
        "          if flip_rand>1:\n",
        "            rainy_img=cv2.flip(rainy_img, 1 )\n",
        "          #rainy_img=cv2.resize(rainy_img,(256,256))\n",
        "          rainy_img=np.transpose(rainy_img, (2, 0, 1))\n",
        "          clean_img=cv2.imread(self.clean_files[index])\n",
        "          clean_img=clean_img[x_rand:x_rand+size,y_rand:y_rand+size,:]\n",
        "          #clean_img[clean_img<0]=0\n",
        "          if flip_rand>1:\n",
        "            clean_img=cv2.flip(clean_img, 1 )\n",
        "          #clean_img=cv2.resize(clean_img,(256,256))\n",
        "          clean_img=np.transpose(clean_img, (2, 0, 1))\n",
        "          clean_img=clean_img/255\n",
        "          rainy_img=rainy_img/255\n",
        "          clean_imgs[i]=clean_img\n",
        "          rainy_imgs[i]=rainy_img\n",
        "        return rainy_imgs,clean_imgs\n",
        "      \n",
        "''' \n",
        "class data_load():\n",
        "    def __init__(self,path_to_clean='train/',batch=5):\n",
        "        super(data_load, self).__init__()\n",
        "        self.clean_files=glob(path_to_clean+'gt/*')\n",
        "        self.path_to_clean=path_to_clean\n",
        "        self.batch=batch\n",
        "        \n",
        "    def next(self):\n",
        "        size=480\n",
        "        clean_imgs=np.zeros((self.batch,3,size,size))\n",
        "        rainy_imgs=np.zeros((self.batch,3,size,size))\n",
        "        for i in range(self.batch):\n",
        "          index=random.randint(0,len(self.clean_files)-1)\n",
        "          flip_rand=random.randint(0,2)\n",
        "          single_clean=self.clean_files[index][9:]\n",
        "          single_clean=single_clean.split('_')[0]\n",
        "          rainy_path=self.path_to_clean+'data/'+single_clean+'_rain.png'\n",
        "          rainy_img=cv2.imread(rainy_path)\n",
        "          x_rand=random.randint(0,rainy_img.shape[0]-size)\n",
        "          y_rand=random.randint(0,rainy_img.shape[1]-size)\n",
        "          rainy_img=rainy_img[x_rand:x_rand+size,y_rand:y_rand+size,:]\n",
        "          #rainy_img=cv2.resize(rainy_img,(480,480))\n",
        "          #rainy_img=rainy_img-int(scale_rand)\n",
        "          #rainy_img[rainy_img<0]=0\n",
        "          if flip_rand>1:\n",
        "            rainy_img=cv2.flip(rainy_img, 1 )\n",
        "            #plt.imshow(rainy_img)\n",
        "            #plt.show()\n",
        "          rainy_img=np.transpose(rainy_img, (2, 0, 1))\n",
        "          clean_img=cv2.imread(self.clean_files[index])\n",
        "          #clean_img=cv2.resize(clean_img,(480,480))\n",
        "          clean_img=clean_img[x_rand:x_rand+size,y_rand:y_rand+size,:]\n",
        "          #clean_img[clean_img<0]=0\n",
        "          if flip_rand>1:\n",
        "            clean_img=cv2.flip(clean_img, 1 )\n",
        "          clean_img=np.transpose(clean_img, (2, 0, 1))\n",
        "          clean_img=clean_img/255\n",
        "          rainy_img=rainy_img/255\n",
        "          clean_imgs[i]=clean_img\n",
        "          rainy_imgs[i]=rainy_img\n",
        "        return rainy_imgs,clean_imgs\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" \\nclass data_load():\\n    def __init__(self,path_to_clean='train/',batch=5):\\n        super(data_load, self).__init__()\\n        self.clean_files=glob(path_to_clean+'gt/*')\\n        self.path_to_clean=path_to_clean\\n        self.batch=batch\\n        \\n    def next(self):\\n        size=480\\n        clean_imgs=np.zeros((self.batch,3,size,size))\\n        rainy_imgs=np.zeros((self.batch,3,size,size))\\n        for i in range(self.batch):\\n          index=random.randint(0,len(self.clean_files)-1)\\n          flip_rand=random.randint(0,2)\\n          single_clean=self.clean_files[index][9:]\\n          single_clean=single_clean.split('_')[0]\\n          rainy_path=self.path_to_clean+'data/'+single_clean+'_rain.png'\\n          rainy_img=cv2.imread(rainy_path)\\n          x_rand=random.randint(0,rainy_img.shape[0]-size)\\n          y_rand=random.randint(0,rainy_img.shape[1]-size)\\n          rainy_img=rainy_img[x_rand:x_rand+size,y_rand:y_rand+size,:]\\n          #rainy_img=cv2.resize(rainy_img,(480,480))\\n          #rainy_img=rainy_img-int(scale_rand)\\n          #rainy_img[rainy_img<0]=0\\n          if flip_rand>1:\\n            rainy_img=cv2.flip(rainy_img, 1 )\\n            #plt.imshow(rainy_img)\\n            #plt.show()\\n          rainy_img=np.transpose(rainy_img, (2, 0, 1))\\n          clean_img=cv2.imread(self.clean_files[index])\\n          #clean_img=cv2.resize(clean_img,(480,480))\\n          clean_img=clean_img[x_rand:x_rand+size,y_rand:y_rand+size,:]\\n          #clean_img[clean_img<0]=0\\n          if flip_rand>1:\\n            clean_img=cv2.flip(clean_img, 1 )\\n          clean_img=np.transpose(clean_img, (2, 0, 1))\\n          clean_img=clean_img/255\\n          rainy_img=rainy_img/255\\n          clean_imgs[i]=clean_img\\n          rainy_imgs[i]=rainy_img\\n        return rainy_imgs,clean_imgs\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZ6YMX_-yPwu"
      },
      "source": [
        "data_loader=data_load(batch=batch)\n",
        "netG=torch.load('gdrive/My Drive/netG.pt')\n",
        "netD=torch.load('gdrive/My Drive/netD.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWOA138ckpv3"
      },
      "source": [
        "def test(rainy,netG):\n",
        "  index=0\n",
        "  generated=netG(rainy)[index]\n",
        "  rainy=rainy[index]\n",
        "  generated=generated.cpu().detach().numpy()\n",
        "  img=rainy.cpu().detach().numpy()\n",
        "  img=np.transpose(img, (1, 2, 0))\n",
        "  generated=np.transpose(generated, (1, 2, 0))\n",
        "  generated[generated<0]=0.0\n",
        "  generated[generated>1]=1.0\n",
        "  plt.imshow(img)\n",
        "  plt.title('rainy')\n",
        "  plt.show()\n",
        "  plt.imshow(generated)\n",
        "  plt.title('de rained')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsdH__4NGOg3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "8582a542-ce3a-4171-dd00-a377eb41293a"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "  netD.zero_grad()\n",
        "  for param in netD.parameters():\n",
        "     param.requires_grad = True\n",
        "  rainy,clean=data_loader.next()\n",
        "  rainy=torch.from_numpy(rainy).to(device).float()\n",
        "  \n",
        "  clean=torch.from_numpy(clean).to(device).float()\n",
        "  generated=netG(rainy).to(device)\n",
        "  D_rainy=netD(generated.detach())\n",
        "  loss=disc_loss(D_rainy,clean,netD)\n",
        "  loss.backward()\n",
        "  optimizer_D.step()\n",
        "  netG.zero_grad()\n",
        "  #netD.zero_grad()\n",
        "  for param in netD.parameters():\n",
        "     param.requires_grad = False\n",
        "  loss2=gen_loss(rainy,clean,netG,netD)\n",
        "  loss2.backward()\n",
        "  optimizer_G.step()\n",
        "  if epoch%display==0:\n",
        "    test(rainy,netG)\n",
        "    print('epoch:',epoch,'Discriminator loss:',loss.item(),'generator loss:',loss2.item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-4c2baebee768>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnetD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m      \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mrainy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mrainy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrainy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-117c75d79de9>\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m           \u001b[0mflip_rand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m           \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m           \u001b[0msingle_clean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m           \u001b[0mrainy_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_to_clean\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'CG_DROPLETS/left'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msingle_clean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/random.py\u001b[0m in \u001b[0;36mrandint\u001b[0;34m(self, a, b)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \"\"\"\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     def _randbelow(self, n, int=int, maxsize=1<<BPF, type=type,\n",
            "\u001b[0;32m/usr/lib/python3.6/random.py\u001b[0m in \u001b[0;36mrandrange\u001b[0;34m(self, start, stop, step, _int)\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mistart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"empty range for randrange() (%d,%d, %d)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mistart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mistop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;31m# Non-unit step argument supplied.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: empty range for randrange() (0,0, 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1lbLHUyTodX"
      },
      "source": [
        "torch.save(netG, 'gdrive/My Drive/netG.pt')\n",
        "torch.save(netD, 'gdrive/My Drive/netD.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFPufgC3KgNi"
      },
      "source": [
        "netG=torch.load('gdrive/My Drive/final weights/Copy of netG.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "245mQ4byFIxe"
      },
      "source": [
        "from google.colab import files\n",
        "!rm case1.jpg\n",
        "files.upload()\n",
        "rainy=plt.imread('case1.jpg')\n",
        "if np.max(rainy)>1.0:\n",
        "  rainy=rainy/255\n",
        "\n",
        "if rainy.shape[0]<rainy.shape[1]:\n",
        "  size=int(rainy.shape[0]/32)*32\n",
        "else:\n",
        "  size=int(rainy.shape[1]/32)*32\n",
        "rainy=cv2.resize(rainy,(size,size))\n",
        "rainy=np.transpose(rainy,[2,0,1])\n",
        "rainy=np.expand_dims(rainy,axis=0)\n",
        "rainy=torch.from_numpy(rainy).to(device).float()\n",
        "test(rainy,netG)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lZHhoeZ4RJw"
      },
      "source": [
        "# PSNR calculation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBWt4uHsjtXv"
      },
      "source": [
        "netG=torch.load('gdrive/My Drive/final weights/Copy of netG.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFso5gVq5QuP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "669066fc-7aa9-4a9b-d898-0240bbcb956a"
      },
      "source": [
        "!ls gdrive/'My Drive'/raindrop_data/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_a.zip  test_b.zip\ttrain.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VHDxAKIj4uy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "1bbc795b-dcf3-4ac0-dd01-b09fc333ca96"
      },
      "source": [
        "from shutil import copyfile\n",
        "#copyfile('gdrive/My Drive/raindrop_data/test_a.zip', 'test_a.zip')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'test_a.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5cTjyzxjzBO"
      },
      "source": [
        "#!unzip test_a.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RhzIA7VjRw-"
      },
      "source": [
        "#ls test_a/data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzW_S-gFjkEb"
      },
      "source": [
        "clean_test_images_files=glob('test_a/gt/*.png')\n",
        "rain_test_images_files=glob('test_a/data/*.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-dfOFS-gPqa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "b165bbe9-22f7-4440-9072-14c2cf81c327"
      },
      "source": [
        "rain_test_images_files[:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['test_a/data/5_rain.png', 'test_a/data/44_rain.png']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsFOAmJDeF-j"
      },
      "source": [
        "def test_metric(rainy,netG):\n",
        "  index=0\n",
        "  generated=netG(rainy)[index]\n",
        "  rainy=rainy[index]\n",
        "  generated=generated.cpu().detach().numpy()\n",
        "  img=rainy.cpu().detach().numpy()\n",
        "  img=np.transpose(img, (1, 2, 0))\n",
        "  generated=np.transpose(generated, (1, 2, 0))\n",
        "  generated[generated<0]=0.0\n",
        "  generated[generated>1]=1.0\n",
        "\n",
        "  return generated"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6A_WVUieXfX"
      },
      "source": [
        "def calc_psnr(im1, im2):\n",
        "    im1_y = cv2.cvtColor(im1, cv2.COLOR_BGR2YCR_CB)[:, :, 0]\n",
        "    im2_y = cv2.cvtColor(im2, cv2.COLOR_BGR2YCR_CB)[:, :, 0]\n",
        "    return compare_psnr(im1_y, im2_y)\n",
        "\n",
        "\n",
        "def calc_ssim(im1, im2):\n",
        "    im1_y = cv2.cvtColor(im1, cv2.COLOR_BGR2YCR_CB)[:, :, 0]\n",
        "    im2_y = cv2.cvtColor(im2, cv2.COLOR_BGR2YCR_CB)[:, :, 0]\n",
        "    return compare_ssim(im1_y, im2_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgX4n2j6eZw_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45953
        },
        "outputId": "4c1e65d1-c3d9-4f28-a67a-f284cc9a17fd"
      },
      "source": [
        "psnr=[]\n",
        "ssim=[]\n",
        "for i in range(len(clean_test_images_files)):\n",
        "  path_to_clean='test_a/gt/'+rain_test_images_files[i][12:].split('_')[0]+'_clean.png'\n",
        "  rainy=plt.imread(rain_test_images_files[i])\n",
        "  if np.max(rainy)>1.0:\n",
        "    rainy=rainy/255\n",
        "\n",
        "  if rainy.shape[0]<rainy.shape[1]:\n",
        "    size=int(rainy.shape[0]/32)*32\n",
        "  else:\n",
        "    size=int(rainy.shape[1]/32)*32\n",
        "  rainy=cv2.resize(rainy,(size,size))\n",
        "  plt.imshow(rainy)\n",
        "  plt.title('rainy')\n",
        "  plt.show()\n",
        "  rainy=np.transpose(rainy,[2,0,1])\n",
        "  rainy=np.expand_dims(rainy,axis=0)\n",
        "  rainy=torch.from_numpy(rainy).to(device).float()\n",
        "  generated=test_metric(rainy,netG)\n",
        "  plt.imshow(generated)\n",
        "  plt.title('generated')\n",
        "  plt.show()\n",
        "  clean=plt.imread(path_to_clean)\n",
        "  if np.max(clean)>1.0:\n",
        "    clean=clean/255\n",
        "\n",
        "  if clean.shape[0]<clean.shape[1]:\n",
        "    size=int(clean.shape[0]/32)*32\n",
        "  else:\n",
        "    size=int(clean.shape[1]/32)*32\n",
        "  clean=cv2.resize(clean,(size,size))\n",
        " \n",
        "  plt.imshow(clean)\n",
        "  plt.title('clean')\n",
        "  plt.show()\n",
        "  psnr.append(calc_psnr(generated,clean))\n",
        "  ssim.append(calc_ssim(generated,clean))\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pwXfL2liSUN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "09e24131-56fc-4fc9-d008-35ad466eb813"
      },
      "source": [
        "np.mean(psnr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19.35939851637655"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C99kZL8SiAng",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "a70abfe4-b8a8-42e6-bc12-a07b054b77dd"
      },
      "source": [
        "np.mean(ssim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.752125042093159"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YeytWwPahUq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "859eae2a-ac75-41af-ee97-74c99c1c03e0"
      },
      "source": [
        "rainy=plt.imread(rain_test_images_files[0])\n",
        "if np.max(rainy)>1.0:\n",
        "  rainy=rainy/255\n",
        "\n",
        "if rainy.shape[0]<rainy.shape[1]:\n",
        "  size=int(rainy.shape[0]/32)*32\n",
        "else:\n",
        "  size=int(rainy.shape[1]/32)*32\n",
        "rainy=cv2.resize(rainy,(size,size))\n",
        "print(rainy.shape)\n",
        "rainy=np.transpose(rainy,[2,0,1])\n",
        "rainy=np.expand_dims(rainy,axis=0)\n",
        "rainy=torch.from_numpy(rainy).to(device).float()\n",
        "generated=test_metric(rainy,netG)\n",
        "print(generated.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(512, 512, 3)\n",
            "(512, 512, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}